{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.13",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "none",
      "dataSources": [
        {
          "sourceId": 111543,
          "databundleVersionId": 13750964,
          "sourceType": "competition"
        },
        {
          "sourceId": 13176071,
          "sourceType": "datasetVersion",
          "datasetId": 8298722
        }
      ],
      "dockerImageVersionId": 31089,
      "isInternetEnabled": false,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": false
    },
    "colab": {
      "name": "HTMP EDA which makes sense ⭐️⭐️⭐️⭐️⭐️",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/xiaopengh/colab/blob/master/HTMP_EDA_which_makes_sense.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "source": [
        "# IMPORTANT: SOME KAGGLE DATA SOURCES ARE PRIVATE\n",
        "# RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES.\n",
        "import kagglehub\n",
        "kagglehub.login()\n"
      ],
      "metadata": {
        "id": "eThtyhN6-7bC"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "source": [
        "# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES,\n",
        "# THEN FEEL FREE TO DELETE THIS CELL.\n",
        "# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON\n",
        "# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR\n",
        "# NOTEBOOK.\n",
        "\n",
        "hull_tactical_market_prediction_path = kagglehub.competition_download('hull-tactical-market-prediction')\n",
        "ambrosm_s_and_p_historical_data_for_hull_tactical_competition_path = kagglehub.dataset_download('ambrosm/s-and-p-historical-data-for-hull-tactical-competition')\n",
        "\n",
        "print('Data source import complete.')\n"
      ],
      "metadata": {
        "id": "xYcs6UCk-7bE"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# EDA which makes sense for the Hull Tactical Market Prediction\n",
        "\n",
        "This EDA shows how to connect the competition dataset with real life; it analyzes the scoring function and shows how to cross-validate a model.\n",
        "\n",
        "Reference:\n",
        "- [Competition](https://www.kaggle.com/competitions/hull-tactical-market-prediction)\n",
        "- Supplementary dataset: [S&P Historical Data for Hull Tactical Competition](https://www.kaggle.com/datasets/ambrosm/s-and-p-historical-data-for-hull-tactical-competition)"
      ],
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "id": "0Ca1QDRp-7bF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from colorama import Fore, Style"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-09-27T11:45:11.219639Z",
          "iopub.execute_input": "2025-09-27T11:45:11.220023Z",
          "iopub.status.idle": "2025-09-27T11:45:11.647901Z",
          "shell.execute_reply.started": "2025-09-27T11:45:11.219997Z",
          "shell.execute_reply": "2025-09-27T11:45:11.646745Z"
        },
        "_kg_hide-input": true,
        "id": "3Ba7nax0-7bG"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Special columns"
      ],
      "metadata": {
        "id": "pjQnUvX9-7bH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The datasets of this competition have some special columns which need an explanation.\n",
        "\n",
        "`train` is historical data of 8990 business days. forward_returns is the column you want to predict. `train.at[8987, 'forward_returns']` is 0.002891. This means that if you invested one dollar in S&P on day 8987 and sold it on the following day, you won 0.002891. If instead of S&P you bought a risk-free investment, you'd have gained only 0.000156 in one day. On day 8987 you would have liked to know these two figures to decide for the better investment, but because the information wasn't yet available, it could only be predicted by a regression model.\n",
        "\n",
        "`test` is data for the period when the model is evaluated. It reflects the information *which is available* on a chosen day. On day 8987, you did not yet know that you could make 0.002891 the following night. You would only get this information one day later. For this reason, `test` has three `lagged_` columns. `test.at[8988, 'lagged_forward_returns']` is 0.002891 because on day 8988 you know that one could have earned either 0.002891 or 0.000156.\n",
        "\n",
        "When the notebook is evaluated for the private leaderboard, `test` will contain days starting with 8990, and Kaggle will present the `test` data to your model row by row. For every row that your model sees, it will have to decide where to invest."
      ],
      "metadata": {
        "id": "MBbpInOg-7bH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train = pd.read_csv('/kaggle/input/hull-tactical-market-prediction/train.csv')\n",
        "train[['date_id', 'forward_returns', 'risk_free_rate', 'market_forward_excess_returns']]"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-09-27T11:45:11.649568Z",
          "iopub.execute_input": "2025-09-27T11:45:11.650128Z",
          "iopub.status.idle": "2025-09-27T11:45:12.077757Z",
          "shell.execute_reply.started": "2025-09-27T11:45:11.65008Z",
          "shell.execute_reply": "2025-09-27T11:45:12.076746Z"
        },
        "id": "X8QEN3Og-7bI"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "test = pd.read_csv('/kaggle/input/hull-tactical-market-prediction/test.csv')\n",
        "test[['date_id', 'is_scored', 'lagged_forward_returns', 'lagged_risk_free_rate', 'lagged_market_forward_excess_returns']]"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-09-27T11:45:12.078874Z",
          "iopub.execute_input": "2025-09-27T11:45:12.079141Z",
          "iopub.status.idle": "2025-09-27T11:45:12.100592Z",
          "shell.execute_reply.started": "2025-09-27T11:45:12.079118Z",
          "shell.execute_reply": "2025-09-27T11:45:12.099597Z"
        },
        "id": "hRbckPNT-7bI"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "The features D1 and D2 are identical in the train dataset. At first, I wanted to drop one of the columns, but we don't know whether they will be different from each other in the private test set."
      ],
      "metadata": {
        "id": "u97wF6Y2-7bJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "(train.D1 == train.D2).mean()"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-09-27T11:45:12.103058Z",
          "iopub.execute_input": "2025-09-27T11:45:12.103329Z",
          "iopub.status.idle": "2025-09-27T11:45:12.111233Z",
          "shell.execute_reply.started": "2025-09-27T11:45:12.103309Z",
          "shell.execute_reply": "2025-09-27T11:45:12.110456Z"
        },
        "id": "IPn6kXRv-7bJ"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Timelines"
      ],
      "metadata": {
        "id": "7QwY7lqb-7bJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "When working with time series, it's usually helpful to plot them in diagrams.\n",
        "\n",
        "A plot of the cumulative forward returns resembles the development of the S&P from 1993 to 2025 (which you can see for instance at https://www.macrotrends.net/2324/sp-500-historical-chart-data). It's not an exact match; some details of the mapping will need to be worked out.\n",
        "\n",
        "![Screenshot 2025-09-17 004253.png](attachment:6d419426-649b-4f4e-b35a-7fd80d718af1.png)"
      ],
      "metadata": {
        "id": "mkg6mviy-7bK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(15, 4))\n",
        "plt.scatter(1990 + train.date_id / 252, (1 + train.forward_returns).cumprod(), s=1)\n",
        "plt.title('The competition data cumulative returns resemble the S & P chart of the last 35 years')\n",
        "plt.yscale('log')\n",
        "plt.xlabel('year')\n",
        "plt.xticks(np.arange(1992, 2025, 4))\n",
        "plt.show()\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-09-27T11:45:12.112219Z",
          "iopub.execute_input": "2025-09-27T11:45:12.11246Z",
          "iopub.status.idle": "2025-09-27T11:45:12.700116Z",
          "shell.execute_reply.started": "2025-09-27T11:45:12.11244Z",
          "shell.execute_reply": "2025-09-27T11:45:12.699193Z"
        },
        "_kg_hide-input": true,
        "id": "odZ8ceH1-7bK"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "A plot of the forward returns shows that they always are between -4 % and +4 %. Periods of high volatility alternate with periods of low volatility:"
      ],
      "metadata": {
        "id": "kC-CSK---7bK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(15, 4))\n",
        "plt.scatter(train.date_id, train.forward_returns, s=1)\n",
        "plt.title('forward_returns')\n",
        "plt.xlabel('date_id')\n",
        "plt.show()"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-09-27T11:45:12.701327Z",
          "iopub.execute_input": "2025-09-27T11:45:12.701602Z",
          "iopub.status.idle": "2025-09-27T11:45:12.950869Z",
          "shell.execute_reply.started": "2025-09-27T11:45:12.701581Z",
          "shell.execute_reply": "2025-09-27T11:45:12.949773Z"
        },
        "_kg_hide-input": true,
        "id": "hsaWUFZP-7bK"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "The competition's `train.csv` contains a `date_id` but no real date. We cannot directly match the `date_id` to the day of the week or to a season of the year.\n",
        "\n",
        "I've uploaded the dataset [S&P Historical Data for Hull Tactical Competition](https://www.kaggle.com/datasets/ambrosm/s-and-p-historical-data-for-hull-tactical-competition) which defines a bijective mapping (row by row) from `date_id` to the real calendar.\n",
        "\n",
        "The dataset contains two files:\n",
        "- sp-historical.csv represents the S&P index for the exact same days as train.csv\n",
        "- spy-historical.csv represents the SPY ETF (SPDR S&P 500 ETF). Its forward returns were computed as `spy['forward_returns'] = (spy['Close'].shift(-1) + spy['Dividend'].shift(-1)) / spy['Close'] - 1`. They match the competition data quite well, but they start only in February of 1993. Thanks to @roberthatch for finding this connection!"
      ],
      "metadata": {
        "id": "H9jF9rd2-7bK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "extra_dataset_sp = pd.read_csv('/kaggle/input/s-and-p-historical-data-for-hull-tactical-competition/sp-historical.csv', parse_dates=['Date'])\n",
        "extra_dataset_spy = pd.read_csv('/kaggle/input/s-and-p-historical-data-for-hull-tactical-competition/spy-historical.csv', parse_dates=['Date'], index_col='date_id')\n",
        "display(extra_dataset_spy.head())"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-09-27T11:45:12.951872Z",
          "iopub.execute_input": "2025-09-27T11:45:12.952156Z",
          "iopub.status.idle": "2025-09-27T11:45:13.055254Z",
          "shell.execute_reply.started": "2025-09-27T11:45:12.952124Z",
          "shell.execute_reply": "2025-09-27T11:45:13.054009Z"
        },
        "id": "f5nKgX1D-7bL"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "We realize now that the competition organizers haven't specified their forward returns precisely. The returns may have been calculated on open/high/low/close values or a combination of them. Moreover they seem to have been winsorized. A scatterplot of the competition dataset versus daily returns from Yahoo Finance shows high correlation, though:"
      ],
      "metadata": {
        "id": "8gbbkCg5-7bL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(12, 6))\n",
        "plt.scatter(extra_dataset_spy.forward_returns, train.forward_returns.iloc[-len(extra_dataset_spy):], s=1)\n",
        "plt.gca().set_aspect('equal')\n",
        "plt.xlabel('downloaded from yahoo finance')\n",
        "plt.ylabel('competition train.csv')\n",
        "plt.title('Comparing forward returns from two sources')\n",
        "plt.savefig('return-scatter.png')\n",
        "plt.show()"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-09-27T11:45:13.056349Z",
          "iopub.execute_input": "2025-09-27T11:45:13.05732Z",
          "iopub.status.idle": "2025-09-27T11:45:13.418506Z",
          "shell.execute_reply.started": "2025-09-27T11:45:13.057284Z",
          "shell.execute_reply": "2025-09-27T11:45:13.417348Z"
        },
        "_kg_hide-input": true,
        "id": "rlLlhnBl-7bL"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can look for seasonality and compute the mean forward returns per day of the week. It looks strange that the Wednesday and Thursday returns are so much smaller than Monday, Tuesday and Friday. The same pattern can be discerned in the lagged means (shifted by one day). If you have an opinion whether these differences are significant, please tell me."
      ],
      "metadata": {
        "id": "RVHXge7Z-7bL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "forward_mean_by_weekday = train.forward_returns.groupby(extra_dataset_sp.Date.dt.dayofweek).mean()\n",
        "lagged_mean_by_weekday = train.forward_returns.shift(1).groupby(extra_dataset_sp.Date.dt.dayofweek).mean()\n",
        "plt.figure(figsize=(12, 2))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.bar(forward_mean_by_weekday.index, forward_mean_by_weekday, color='chocolate')\n",
        "plt.xticks(np.arange(5), ['Mon', 'Tue', 'Wed', 'Thu', 'Fri'])\n",
        "plt.title('Mean forward returns by day of week')\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.bar(lagged_mean_by_weekday.index, lagged_mean_by_weekday, color='chocolate')\n",
        "plt.xticks(np.arange(5), ['Mon', 'Tue', 'Wed', 'Thu', 'Fri'])\n",
        "plt.title('Mean lagged returns by day of week')\n",
        "plt.show()\n",
        "\n",
        "# import scipy.stats\n",
        "# train.forward_returns.groupby(extra_dataset_sp.Date.dt.dayofweek).agg(scipy.stats.sem)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-09-27T11:45:13.419566Z",
          "iopub.execute_input": "2025-09-27T11:45:13.41994Z",
          "iopub.status.idle": "2025-09-27T11:45:13.656696Z",
          "shell.execute_reply.started": "2025-09-27T11:45:13.419903Z",
          "shell.execute_reply": "2025-09-27T11:45:13.655681Z"
        },
        "_kg_hide-input": true,
        "id": "xrPxIKH4-7bL"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "The plot of the risk-free rate shows rates between 0 and 0.03 % per day, which corresponds to 12 % per year. (?)"
      ],
      "metadata": {
        "id": "r1yjl_sJ-7bL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(15, 4))\n",
        "plt.scatter(train.date_id, train.risk_free_rate, s=1)\n",
        "plt.title('risk_free_rate')\n",
        "plt.xlabel('date_id')\n",
        "plt.show()"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-09-27T11:45:13.659369Z",
          "iopub.execute_input": "2025-09-27T11:45:13.659659Z",
          "iopub.status.idle": "2025-09-27T11:45:13.864368Z",
          "shell.execute_reply.started": "2025-09-27T11:45:13.659638Z",
          "shell.execute_reply": "2025-09-27T11:45:13.863408Z"
        },
        "_kg_hide-input": true,
        "jupyter": {
          "source_hidden": true
        },
        "id": "e8GMlBtc-7bL"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "The chart of the market forward excess returns resembles the chart of the forward returns which we've seen above."
      ],
      "metadata": {
        "id": "6JqY-tgX-7bM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(15, 4))\n",
        "plt.scatter(train.date_id, train.market_forward_excess_returns, s=1)\n",
        "plt.title('market_forward_excess_returns')\n",
        "plt.xlabel('date_id')\n",
        "plt.show()"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-09-27T11:45:13.865274Z",
          "iopub.execute_input": "2025-09-27T11:45:13.8655Z",
          "iopub.status.idle": "2025-09-27T11:45:14.088724Z",
          "shell.execute_reply.started": "2025-09-27T11:45:13.865483Z",
          "shell.execute_reply": "2025-09-27T11:45:14.087656Z"
        },
        "jupyter": {
          "source_hidden": true
        },
        "id": "ltk3FtCi-7bM"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "The difference between forward returns and market forward excess returns resembles the chart of the risk-free rate:"
      ],
      "metadata": {
        "id": "FbSby85K-7bM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(15, 4))\n",
        "plt.scatter(train.date_id, train.forward_returns - train.market_forward_excess_returns, s=1)\n",
        "plt.title('forward_returns - market_forward_excess_returns')\n",
        "plt.xlabel('date_id')\n",
        "plt.show()"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-09-27T11:45:14.090135Z",
          "iopub.execute_input": "2025-09-27T11:45:14.090513Z",
          "iopub.status.idle": "2025-09-27T11:45:14.28559Z",
          "shell.execute_reply.started": "2025-09-27T11:45:14.090477Z",
          "shell.execute_reply": "2025-09-27T11:45:14.28436Z"
        },
        "_kg_hide-input": true,
        "jupyter": {
          "source_hidden": true
        },
        "id": "cZIRIo3M-7bM"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Understanding the competition task and the scoring function\n",
        "\n",
        "Having seen the most important columns of the dataset, we now want to understand the competition task and the scoring.\n",
        "\n",
        "The task: Every day, we have to decide how much of our money we invest in S & P. Our allocation must be between 0 and 2:\n",
        "- 0 means that we don't invest in S & P at all but get only the risk-free rate.\n",
        "- 1 means that we invest all our money in S & P.\n",
        "- 2 means that we invest twice our capital in S & P while taking a credit at the risk-free rate.\n",
        "\n",
        "The simplest possible strategy works with a constant allocation: Every day, we invest the same fraction of the capital in S & P. We now plot the score that we'd get for constant allocations between 0 and 2:"
      ],
      "metadata": {
        "id": "sxjAll52-7bM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "MIN_INVESTMENT = 0\n",
        "MAX_INVESTMENT = 2\n",
        "\n",
        "\n",
        "class ParticipantVisibleError(Exception):\n",
        "    pass\n",
        "\n",
        "\n",
        "def score(solution: pd.DataFrame, submission: pd.DataFrame, row_id_column_name: str) -> float:\n",
        "    \"\"\"\n",
        "    Calculates a custom evaluation metric (volatility-adjusted Sharpe ratio).\n",
        "\n",
        "    This metric penalizes strategies that take on significantly more volatility\n",
        "    than the underlying market.\n",
        "\n",
        "    Returns:\n",
        "        float: The calculated adjusted Sharpe ratio.\n",
        "    \"\"\"\n",
        "    solution = solution\n",
        "    solution['position'] = submission['prediction']\n",
        "\n",
        "    if solution['position'].max() > MAX_INVESTMENT:\n",
        "        raise ParticipantVisibleError(f'Position of {solution[\"position\"].max()} exceeds maximum of {MAX_INVESTMENT}')\n",
        "    if solution['position'].min() < MIN_INVESTMENT:\n",
        "        raise ParticipantVisibleError(f'Position of {solution[\"position\"].min()} below minimum of {MIN_INVESTMENT}')\n",
        "\n",
        "    solution['strategy_returns'] = solution['risk_free_rate'] * (1 - solution['position']) + solution['position'] * solution['forward_returns']\n",
        "\n",
        "    # Calculate strategy's Sharpe ratio\n",
        "    strategy_excess_returns = solution['strategy_returns'] - solution['risk_free_rate']\n",
        "    strategy_excess_cumulative = (1 + strategy_excess_returns).prod()\n",
        "    strategy_mean_excess_return = (strategy_excess_cumulative) ** (1 / len(solution)) - 1\n",
        "    strategy_std = solution['strategy_returns'].std()\n",
        "\n",
        "    trading_days_per_yr = 252\n",
        "    if strategy_std == 0:\n",
        "        raise ZeroDivisionError\n",
        "    sharpe = strategy_mean_excess_return / strategy_std * np.sqrt(trading_days_per_yr)\n",
        "    strategy_volatility = float(strategy_std * np.sqrt(trading_days_per_yr) * 100)\n",
        "\n",
        "    # Calculate market return and volatility\n",
        "    market_excess_returns = solution['forward_returns'] - solution['risk_free_rate']\n",
        "    market_excess_cumulative = (1 + market_excess_returns).prod()\n",
        "    market_mean_excess_return = (market_excess_cumulative) ** (1 / len(solution)) - 1 # train: 0.0003066067595838273\n",
        "    market_std = solution['forward_returns'].std()\n",
        "\n",
        "    market_volatility = float(market_std * np.sqrt(trading_days_per_yr) * 100) # train: 16.748459963166347 %\n",
        "\n",
        "    # Calculate the volatility penalty\n",
        "    excess_vol = max(0, strategy_volatility / market_volatility - 1.2) if market_volatility > 0 else 0\n",
        "    vol_penalty = 1 + excess_vol\n",
        "\n",
        "    # Calculate the return penalty\n",
        "    return_gap = max(\n",
        "        0,\n",
        "        (market_mean_excess_return - strategy_mean_excess_return) * 100 * trading_days_per_yr,\n",
        "    )\n",
        "    return_penalty = 1 + (return_gap**2) / 100\n",
        "\n",
        "    # Adjust the Sharpe ratio by the volatility and return penalty\n",
        "    adjusted_sharpe = sharpe / (vol_penalty * return_penalty)\n",
        "    try:\n",
        "        intermediate_res.append((strategy_mean_excess_return, strategy_std, sharpe, vol_penalty, return_penalty))\n",
        "    except NameError:\n",
        "        pass\n",
        "    return min(float(adjusted_sharpe), 1_000_000)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-09-27T11:45:14.286679Z",
          "iopub.execute_input": "2025-09-27T11:45:14.287033Z",
          "iopub.status.idle": "2025-09-27T11:45:14.298657Z",
          "shell.execute_reply.started": "2025-09-27T11:45:14.287004Z",
          "shell.execute_reply": "2025-09-27T11:45:14.297532Z"
        },
        "_kg_hide-input": true,
        "id": "I4B89sKD-7bM"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "allocation_range = np.linspace(0, 2, 200)[1:]\n",
        "res = []\n",
        "intermediate_res = [] # will be filled by our modified scoring function\n",
        "for allocation in allocation_range:\n",
        "    submission = pd.DataFrame({'prediction': np.ones(len(train)) * allocation}, index=train.index)\n",
        "    res.append(score(train.copy(), submission, ''))\n",
        "\n",
        "plt.figure(figsize=(6, 9))\n",
        "plt.subplot(6, 1, (1, 3))\n",
        "plt.scatter(allocation_range, res, s=1, color='lightgreen')\n",
        "plt.xlabel('allocation')\n",
        "plt.ylabel('score')\n",
        "plt.axvline(1, color='gray')\n",
        "plt.axvline(1.2, color='gray')\n",
        "plt.title('Score for constant allocations')\n",
        "\n",
        "plt.subplot(6, 1, 4)\n",
        "plt.scatter(allocation_range, [i[2] for i in intermediate_res], s=1)\n",
        "plt.title('Sharpe ratio')\n",
        "plt.xlabel('allocation')\n",
        "\n",
        "plt.subplot(6, 1, 5)\n",
        "plt.scatter(allocation_range, [i[3] for i in intermediate_res], s=1)\n",
        "plt.xticks(np.linspace(0, 2, 11))\n",
        "plt.title('vol_penalty')\n",
        "plt.xlabel('allocation')\n",
        "\n",
        "plt.subplot(6, 1, 6)\n",
        "plt.scatter(allocation_range, [i[4] for i in intermediate_res], s=1)\n",
        "plt.title('return_penalty')\n",
        "plt.xlabel('allocation')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-09-27T11:45:14.299798Z",
          "iopub.execute_input": "2025-09-27T11:45:14.300233Z",
          "iopub.status.idle": "2025-09-27T11:45:15.737974Z",
          "shell.execute_reply.started": "2025-09-27T11:45:14.300202Z",
          "shell.execute_reply": "2025-09-27T11:45:15.736919Z"
        },
        "_kg_hide-input": true,
        "id": "B20z0AJ--7bN"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "The diagrams show:\n",
        "1. We get the highest score with a constant allocation near 0.8.\n",
        "2. The Sharpe ratio doesn't depend much on our strategy. With every constant strategy, the Sharpe ratio is between 0.4 and 0.5.\n",
        "3. Allocations above 1.2 get punished with a volatility penalty: The volatility penalty is defined as the difference between our strategy's volatility and 1.2 times the market volatility.\n",
        "4. Allocations below 1.0 get punished with a return penalty: The return penalty is the square of how much our strategy is below an allocation of 1.0 in S & P.\n",
        "\n",
        "In short: We want to allocate our money so that we get high returns with bounded volatility.\n",
        "\n",
        "For details see the [source code of the scoring function](https://www.kaggle.com/code/metric/hull-competition-sharpe)."
      ],
      "metadata": {
        "id": "pqeYtdOX-7bN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# A simple allocation strategy based on the previous quarter's volatility\n",
        "\n",
        "Having seen that the time series has alternating periods of high and low volatility, we can define a simple strategy: If the previous quarter's volatility is low, make a high allocation and vice versa.\n",
        "\n",
        "This strategy gives us a score of 0.52 on the training data, somewhat more than the constant strategy:"
      ],
      "metadata": {
        "id": "JXHQ_fEr-7bN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# The parameters w, f and o were determined by trial and error\n",
        "w = 80\n",
        "f = 45\n",
        "o = 0.006\n",
        "train['last_week_volatility'] = train['forward_returns'].rolling(window=w).std().shift(1).fillna(0.04)\n",
        "intermediate_res = []\n",
        "submission = pd.DataFrame({'prediction': 1 + o * f - train['last_week_volatility'] * f}, index=train.index).clip(0, 2)\n",
        "print(f\"Score: {score(train.copy(), submission, '')}\")\n",
        "print(f\"Volatility penalty: {intermediate_res[-1][3]:.2f} (1.00 is the optimum)\")\n",
        "print(f\"Return  penalty:    {intermediate_res[-1][4]:.2f} (1.00 is the optimum)\")\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-09-27T11:45:15.739184Z",
          "iopub.execute_input": "2025-09-27T11:45:15.739452Z",
          "iopub.status.idle": "2025-09-27T11:45:15.790044Z",
          "shell.execute_reply.started": "2025-09-27T11:45:15.739431Z",
          "shell.execute_reply": "2025-09-27T11:45:15.788996Z"
        },
        "id": "2ifzgSJg-7bN"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "The two diagrams show that indeed in periods of high volatility the allocations are lower than in periods of low volatility:"
      ],
      "metadata": {
        "id": "pzyoi5xY-7bN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "_, ax = plt.subplots(2, 1, sharex=True, figsize=(15, 8))\n",
        "ax[0].scatter(train.date_id, submission.prediction, s=1, color='m')\n",
        "ax[0].set_title('allocation with the simple allocation strategy')\n",
        "ax[0].set_xlabel('date_id')\n",
        "\n",
        "ax[1].scatter(train.date_id, train.forward_returns, s=1)\n",
        "ax[1].set_title('forward_returns')\n",
        "ax[1].set_xlabel('date_id')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-09-27T11:45:15.791155Z",
          "iopub.execute_input": "2025-09-27T11:45:15.791583Z",
          "iopub.status.idle": "2025-09-27T11:45:16.212282Z",
          "shell.execute_reply.started": "2025-09-27T11:45:15.791559Z",
          "shell.execute_reply": "2025-09-27T11:45:16.211313Z"
        },
        "id": "iVRVZmeH-7bN"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "What is the weakness of this simple strategy? It optimizes only the volatility but doesn't consider the expected returns. Combine the two and you'll win the competition..."
      ],
      "metadata": {
        "id": "XsAA5uHU-7bN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Correct cross-validation\n",
        "\n",
        "In the previous section of this notebook, we have computed a score for our models on the training data but we don't know how well they generalize. To evaluate the generalization capability, we need to evaluate a model on data which it hasn't seen during training.\n",
        "\n",
        "The dataset is small: with 8990 rows it's easy to overfit, all the more if you only validate on a single train–test split. Cross-validation on mulitple folds is a necessity.\n",
        "\n",
        "Correct cross-validation is not easy with time series. You may use the following function as a basis for cross-validation, or you can work with scikit-learn's `TimeSeriesSplit`.\n",
        "\n",
        "Note that the [leaderboard scores are completely misleading](https://www.kaggle.com/competitions/hull-tactical-market-prediction/discussion/608088) in this competition."
      ],
      "metadata": {
        "id": "tqt0eu07-7bN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import polars as pl\n",
        "\n",
        "score_list_dict = {}\n",
        "\n",
        "def cross_validate(allocation_model, label='', min_train_size=1500, test_size=120):\n",
        "    \"\"\"Print the validation score for allocation_model and the given train–test split.\n",
        "\n",
        "    Parameters:\n",
        "    allocation_model: object with methods fit and predict\n",
        "    label: the name of the model\n",
        "    min_train_size: minimum number of samples for training, taken from the beginning of the training dataset\n",
        "    test_size: number of samples for testing, taken from the time period immediately after the training\n",
        "    \"\"\"\n",
        "    # Read the training dataset\n",
        "    train = pl.read_csv('/kaggle/input/hull-tactical-market-prediction/train.csv')\n",
        "\n",
        "    oof = np.full(len(train), np.nan)\n",
        "    score_list = []\n",
        "    for fold, test_start in enumerate(range(len(train) - test_size, min_train_size, - test_size)):\n",
        "\n",
        "        # Split into train and test\n",
        "        # test has lagged targets rather than current targets\n",
        "        test_preliminary = train.slice(test_start, test_size)\n",
        "        solution = pd.DataFrame(test_preliminary.select('forward_returns', 'risk_free_rate'),\n",
        "                                columns=['forward_returns', 'risk_free_rate'])\n",
        "        lagged = train.slice(test_start - 1, test_size)\n",
        "        test = (\n",
        "            test_preliminary\n",
        "            .drop('forward_returns', 'risk_free_rate', 'market_forward_excess_returns')\n",
        "            .with_columns(\n",
        "                lagged.get_column('forward_returns').alias('lagged_forward_returns'),\n",
        "                lagged.get_column('risk_free_rate').alias('lagged_risk_free_rate'),\n",
        "                lagged.get_column('market_forward_excess_returns').alias('lagged_market_forward_excess_returns'),\n",
        "            )\n",
        "        )\n",
        "        del test_preliminary\n",
        "        train1 = train.slice(0, test_start)\n",
        "        # print(train1)\n",
        "        # print(test)\n",
        "\n",
        "        # Fit the model\n",
        "        allocation_model.fit(train1)\n",
        "\n",
        "        # Predict for validation\n",
        "        assert test['date_id'].is_sorted()\n",
        "        allocation_list = []\n",
        "        batch_ids = test['date_id'].unique(maintain_order=True).to_list()\n",
        "        for batch_id in batch_ids:\n",
        "            test_batch = test.filter(pl.col('date_id') == batch_id)\n",
        "            allocation_list.append(allocation_model.predict(test_batch))\n",
        "\n",
        "        # Score the validation predictions of this fold\n",
        "        allocation_list = np.array(allocation_list, dtype=np.float32)\n",
        "        submission = pl.DataFrame({'prediction': allocation_list})\n",
        "        validation_score = score(solution, submission, '')\n",
        "        vol_penalty = intermediate_res[-1][3]\n",
        "        return_penalty = intermediate_res[-1][4]\n",
        "        if fold <= 2 or fold >= 59:\n",
        "            print(f\"# Fold {fold:2} train(:{test_start:4}) test({test_start:4}:{test_start+test_size:4}) val_score: {validation_score:6.3f} {vol_penalty=:.2f} {return_penalty=:.2f}\")\n",
        "        if fold == 2:\n",
        "            print('...')\n",
        "        oof[test_start:test_start+test_size] = allocation_list\n",
        "        score_list.append(validation_score)\n",
        "\n",
        "    # Score the validation predictions overall\n",
        "    print(f\"{Fore.RED}# Average validation score: {np.array(score_list).mean():6.3f}\", end='   ')\n",
        "    solution = pd.DataFrame(train.select('forward_returns', 'risk_free_rate'),\n",
        "                                columns=['forward_returns', 'risk_free_rate'])\n",
        "    submission = pl.DataFrame({'prediction': oof[np.isfinite(oof)]})\n",
        "    validation_score = score(solution[np.isfinite(oof)].copy(), submission, '')\n",
        "    print(f\"Overall validation score: {validation_score:6.3f} {label}{Style.RESET_ALL}\")\n",
        "    score_list_dict[label] = score_list\n",
        "\n",
        "    # Show a histogram of the predictions\n",
        "    plt.figure(figsize=(6, 2))\n",
        "    plt.hist(oof, bins=np.linspace(0, 2, 81), density=True, color='c')\n",
        "    plt.title(f'Allocation histogram of {label}')\n",
        "    plt.gca().get_yaxis().set_visible(False)\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-09-27T11:45:16.213623Z",
          "iopub.execute_input": "2025-09-27T11:45:16.214028Z",
          "iopub.status.idle": "2025-09-27T11:45:17.004273Z",
          "shell.execute_reply.started": "2025-09-27T11:45:16.213996Z",
          "shell.execute_reply": "2025-09-27T11:45:17.003064Z"
        },
        "id": "RY49jE9b-7bO"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "We define two models and compare them with the cross-validation function. The models have functions `fit()` and `predict()`, but the calling convention differs from scikit-learn: `predict()` doesn't predict a target but decides how many funds to allocate to S&P.\n",
        "\n",
        "The LinearAllocationModel scores slightly better than the ConstantAllocationModel:"
      ],
      "metadata": {
        "id": "ziZT1-Tm-7bO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.linear_model import Ridge\n",
        "\n",
        "class ConstantAllocationModel:\n",
        "    \"\"\"A model which ignores all features and always predicts the allocation given to __init__\"\"\"\n",
        "    def __init__(self, constant_allocation):\n",
        "        self.constant_allocation = constant_allocation\n",
        "\n",
        "    def fit(self, train: pl.DataFrame):\n",
        "        pass\n",
        "\n",
        "    def predict(self, test: pl.DataFrame) -> float:\n",
        "        \"\"\"Return the optimal allocation between 0.0 and 2.0.\n",
        "\n",
        "        Parameter:\n",
        "        test: polars DataFrame with a single row (which is ignored)\n",
        "        \"\"\"\n",
        "        return self.constant_allocation\n",
        "\n",
        "class LinearAllocationModel:\n",
        "    \"\"\"A linear model which predicts returns based on a feature subset and\n",
        "    computes the allocation as a function of the predicted returns.\n",
        "\n",
        "    This model neglects the volatility.\"\"\"\n",
        "    vars_to_keep = ['M3', 'V2', 'P13', 'E14', 'S5', 'S4', 'S11',\n",
        "                    'P10', 'P8', 'E3', 'P6', 'E20', 'P11', 'M12']\n",
        "\n",
        "    def __init__(self):\n",
        "        pass\n",
        "\n",
        "    def fit(self, train: pl.DataFrame):\n",
        "        train = train.select(type(self).vars_to_keep + ['forward_returns', 'risk_free_rate', 'market_forward_excess_returns'])\n",
        "        train = train.slice(1006) # the first 1006 rows have too many missing values\n",
        "        self.prediction_model = make_pipeline(SimpleImputer(), Ridge())\n",
        "        self.prediction_model.fit(np.array(train.select(type(self).vars_to_keep)),\n",
        "                                  train.get_column('forward_returns'))\n",
        "\n",
        "    def predict(self, test: pl.DataFrame) -> float:\n",
        "        \"\"\"Return the optimal allocation between 0.0 and 2.0.\n",
        "\n",
        "        Parameter:\n",
        "        test: polars DataFrame with a single row\n",
        "        \"\"\"\n",
        "        predicted_returns = self.prediction_model.predict(\n",
        "            np.array(test.select(type(self).vars_to_keep))\n",
        "        )\n",
        "        predicted_returns = predicted_returns.item()\n",
        "        allocation = predicted_returns * 150 + 1\n",
        "        return np.clip(allocation, 0, 2)\n",
        "\n",
        "test_size = 200\n",
        "cross_validate(ConstantAllocationModel(0.8), label='ConstantAllocationModel 0.8')\n",
        "cross_validate(ConstantAllocationModel(1.2), label='ConstantAllocationModel 1.2')\n",
        "cross_validate(LinearAllocationModel(), label='LinearAllocationModel')\n",
        "# Average validation score:  0.607   Overall validation score:  0.451 ConstantAllocationModel\n",
        "# Average validation score:  0.902   Overall validation score:  0.475 LinearAllocationModel\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-09-27T11:45:17.005519Z",
          "iopub.execute_input": "2025-09-27T11:45:17.00588Z",
          "iopub.status.idle": "2025-09-27T11:45:48.111996Z",
          "shell.execute_reply.started": "2025-09-27T11:45:17.00585Z",
          "shell.execute_reply": "2025-09-27T11:45:48.110919Z"
        },
        "id": "megt8fsW-7bW"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "Note the huge difference between the average validation score (average of the per-fold scores) and the overall validation score. This difference is a consequence of the competition metric: The expected volatility in a 100-day fold is smaller than the expected volatility over a 35-year period.\n",
        "\n",
        "Plotting the single-fold scores, we see that in most folds the LinearAllocationModel scores higher than the ConstantAllocationModel:"
      ],
      "metadata": {
        "id": "9S0TaeID-7bW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(12, 4))\n",
        "for k, v in score_list_dict.items():\n",
        "    plt.plot(v, label=k)\n",
        "plt.legend()\n",
        "plt.xlabel('fold')\n",
        "plt.ylabel('validation score')\n",
        "plt.title('Model comparison by cross-validation fold')\n",
        "plt.show()"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-09-27T11:45:48.113066Z",
          "iopub.execute_input": "2025-09-27T11:45:48.113616Z",
          "iopub.status.idle": "2025-09-27T11:45:48.356534Z",
          "shell.execute_reply.started": "2025-09-27T11:45:48.113587Z",
          "shell.execute_reply": "2025-09-27T11:45:48.355569Z"
        },
        "_kg_hide-input": true,
        "id": "cd9MDSQZ-7bW"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "As you can see, the validation scores depend very much on the time period chosen. That's life: financial markets have good years and bad years.\n",
        "\n",
        "# Insight\n",
        "\n",
        "This time series competition is not simply about predicting a target with minimal error. Beyond predicting the target (the expected returns), we need to quantify our prediction's uncertainty (the volatility). And then we don't simply submit the predictions but optimize our money allocation given these predictions and the quantified uncertainty.\n",
        "\n",
        "Good luck!"
      ],
      "metadata": {
        "id": "4kLGvueE-7bW"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "trusted": true,
        "id": "mpX6RAzi-7bW"
      },
      "outputs": [],
      "execution_count": null
    }
  ]
}